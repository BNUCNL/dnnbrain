#! /usr/bin/env python

import os
import sys
import h5py
import time
import copy
import torch
import argparse
from PIL import Image
from torchvision import transforms
from dnnbrain.dnn.io import NetLoader
from dnnbrain.dnn.io import read_stim_csv,read_dmask_csv,save_stim_csv
from dnnbrain.dnn.analyzer import dnn_count_top,lay_chn_to_dmask_dict,dnn_activation

def main():

    parser = argparse.ArgumentParser(description = 'Select top stimuli from '
                                     'a set of stimuli for interested layers & channel.')

    parser.add_argument('-net',metavar = 'Name of interested DNN',
                        type = str,required = False,
                        help = 'Name of interested DNN net')

    parser.add_argument('-top',metavar = 'The number of stimuli to be selected',
                        type = int,required = False,
                        help = 'Top N stimuli will be selected.')

    parser.add_argument('-metric',metavar = 'The metric of top K',
                        type = str,required = False,
                        help = 'The metric of top K.mean,max,L1,L2')

    parser.add_argument('-stimdir',metavar = 'A path for stimuli of interest',
                        type = str,required = False,
                        help = 'A path for stimuli of interest')

    parser.add_argument('-layer',nargs = '+',metavar = 'Layer',
                        type = str,required = False,default = None,
                        help = 'Layers of interest. '
                                'conv, relu, pool, fc represents convolution, reLU, '
                                'pooling, and full connection layer, respectively.'
                                'Default, the top stimulis are selected for '
                                'all layers and all channels.')

    parser.add_argument('-channel',nargs = '+',metavar = 'Channel id list',
                        type = int,required = False,default = None,
                        help = "Channel of interest. ")

    parser.add_argument('-dmask',metavar = '.dmask.csv dnnmask file',
                        type = str,required = False,default = None,
                        help = "A *.dmask.csv list of interested layers and channels. " )

    parser.add_argument('-outdir',metavar='an output stim.hd5 file',
                        type = str,required = False,
                        help = 'Output dir to save the top stimulus for '
                        'interested layers and channels, and assocaited '
                        'topact.hd5 file')

    args = parser.parse_args()

    if not os.path.exists(args.outdir):
        os.mkdir(args.outdir)

    net_loader = NetLoader(args.net)
    stim_dict = read_stim_csv(args.stimdir)

    assert args.dmask == None or args.channel == None,'-layer -channel & -dmask is exclusive!'

    if args.layer == None:
        dmask_dict = read_dmask_csv(args.dmask)
    else:
        dmask_dict = lay_chn_to_dmask_dict(args.layer,args.channel)

    transform = transforms.Compose([transforms.Resize(net_loader.img_size), transforms.ToTensor()])

    print('start calculating...')

    img_set = torch.zeros([len(stim_dict['stim']['stimID']),3,net_loader.img_size[0],net_loader.img_size[0]])

    for i in enumerate(stim_dict['stim']['stimID']):
        img_set[i[0]] = transform(Image.open(stim_dict['path'] + '\\'+i[1]))

    for ly in list(dmask_dict.keys()):
        h5_name = args.net+'.'+ly+'.'+os.path.basename(args.stimdir).rstrip('.stim.csv')+'.act.h5'
        if not os.path.exists(args.outdir+'\\'+h5_name):
            dnn_acts = dnn_activation(img_set, net_loader.model,net_loader.layer2keys[ly])
            wf = h5py.File(args.outdir+'\\'+h5_name, 'w')
            wf.attrs['title'] = h5_name.rstrip('.act.h5')
            wf.attrs['cmd'] = ' '.join(sys.argv)
            wf.attrs['date'] = time.asctime()
            dset = wf.create_dataset(name = ly,data=dnn_acts)
            dset.attrs['raw_shape'] = [args.top,256,13,13]
            wf.close
        rf = h5py.File(args.outdir+'\\'+h5_name, 'r')
        top_result = dnn_count_top(rf[ly][()],stim_dict,args.top,args.metric,dmask_dict[ly]['chn'])
        print(h5_name + ' is counted!')
        for chn in enumerate(dmask_dict[ly]['chn']):
            csv_name = args.net+'.'+'top'+str(args.top)+'.'+args.metric+'.'+ly+\
            '.'+str(chn[1])+'.'+os.path.basename(args.stimdir)
            if not os.path.exists(args.outdir+'\\'+csv_name):
                tmp_stim_dict = copy.deepcopy(stim_dict)
                tmp_stim_dict['stim']['stimID'] = tmp_stim_dict['stim']['stimID'][list(top_result[chn[0]])]
                tmp_stim_dict['stim']['condition'] = tmp_stim_dict['stim']['condition'][list(top_result[chn[0]])]
                save_stim_csv(args.outdir+'\\'+csv_name,tmp_stim_dict['title'],tmp_stim_dict['type'],\
                              tmp_stim_dict['path'],tmp_stim_dict['stim'])

if __name__ == '__main__':
    a= main()