#! /usr/bin/env python

import numpy as np
import os, copy, argparse, collections

from os.path import join as pjoin
from os.path import exists as pexist

from torchvision import transforms
from torch.utils.data import DataLoader

import dnnbrain.dnn.io as dio
import dnnbrain.utils.io as uio
import dnnbrain.dnn.analyzer as dan


def main():

    parser = argparse.ArgumentParser(description='Select top K stimuli from '
                                     'a set of stimulus for interested layers and channels. ')

    parser.add_argument('-net',
                        metavar='DNN_model_name',
                        type=str, required=True,
                        help='Name of interested DNN net.The DNN net should be placed '
                                'in system variable DNNBRAIN_MODEL_DIR with format *.pth . ')

    parser.add_argument('-top',
                        metavar='top_stimulus_num',
                        type=int, required=True,
                        help='Number of top stimulus.For example, top = 5, and the '
                                '*.stim.csv file for top5 image for each pair <layer,channel> '
                                'will be generated. ')

    parser.add_argument('-metric',
                        metavar='metric_of_top_K',
                        type=str, required=True,
                        help='The metric of top K. Available args are: mean, max, L1, L2, median. ')

    parser.add_argument('-stim',
                        metavar='stimulus_path',
                        type=str, required=True,
                        help='A *.stim.csv file contained interested stimuli. ')

    parser.add_argument('-layer', nargs='+',
                        metavar='layer',
                        type=str, required=False, default=None,
                        help='Interested layers'
                                'conv, relu, pool, fc represents convolution, reLU, '
                                'pooling, and full connection layer, respectively.'
                                'Default, the top stimulis are selected for '
                                'all layers and all channels. ')

    parser.add_argument('-channel', nargs='+',
                        metavar='channel_ID_list',
                        type=int, required=False, default=None,
                        help='Channel of interest. ')

    parser.add_argument('-dmask',
                        metavar='.dmask.csv dnnmask file',
                        type=str, required=False, default=None,
                        help='A *.dmask.csv list of interested layers and channels. ')

    parser.add_argument('-out',
                        metavar='Output stim.hd5 file',
                        type=str, required=True, default=None,
                        help='Output dir to save the top stimulus for interested layers '
                                'and channels, and assocaited *.act.hd5 file. ')

    args = parser.parse_args()

    # --- judge availability of input ---
    assert args.metric in ['L1', 'L2', 'mean', 'max', 'median'],\
        'The input -metric is no supported! Supported -metric for top K stimulus are mean, max, L1, L2, median. '
    if not pexist(args.out):
        os.mkdir(args.out)
    if args.dmask is None:
        assert args.layer is not None,\
            'When -dmask does not exist, please assign -layer. Then if you assign -channel, I will calculate '
        'specific channel you assign for each layer, else I will calculate all channel in each layer. '
        if type(args.layer) is list and type(args.channel) is list:
            assert len(args.layer) == len(args.channel),\
                'If -layer and -channel are lists, be sure that the length of layer and channel is equal. '
            'Then I will calculate each pair of layer and channel. '
    else:
        assert args.layer is None and args.channel is None,\
            'If -dmask already exists, -layer and -channel should not exists. '

    # --- load DNN ---
    model = dio.NetLoader(args.net)

    # --- load dmask or generate dmask ---
    if args.layer is None:
        dmask_dict = dio.read_dmask_csv(args.dmask)
    else:
        dmask_dict = collections.OrderedDict()
        if isinstance(args.layer, str) and isinstance(args.channel, int):
            dmask_dict[args.layer] = {'chn': args.channel, 'col': None}
        if isinstance(args.layer, list) and isinstance(args.channel, list):
            for i in range(0, len(args.layer)):
                dmask_dict[args.layer[i]] = {'chn': args.channel[i], 'col': None}
        if isinstance(args.layer, str) and args.channel is None:
            dmask_dict[args.layer] = {'chn': 'all', 'col': None}
        if isinstance(args.layer, list) and args.channel is None:
            for i in enumerate(args.layer):
                dmask_dict[args.layer[i[0]]] = {'chn': 'all', 'col': None}

    # --- load stimulus ---
    stim_dict = uio.read_stim_csv(args.stim)
    transimg2tensor = transforms.Compose([transforms.Resize(model.img_size), transforms.ToTensor()])
    dataset = dio.ImgDataset(stim_dict['path'], stim_dict['stim']['stimID'], transform=transimg2tensor)
    data_loader = DataLoader(dataset, batch_size=8, shuffle=False)

    for ly in dmask_dict.keys():
        # --- extract activation ---
        title = args.net + '.' + os.path.basename(args.stim).rstrip('.stim.csv') + '.' + ly + '.act.h5'
        if not pexist(pjoin(args.out, title)):
            n_stim = len(dataset)
            writer = dio.ActWriter(pjoin(args.out, title), title)
            tmp_act = []
            for stims, _ in data_loader:
                tmp_act.extend(dan.dnn_activation(stims, model.model, model.layer2loc[ly]))
                print('Extracted acts: {0}/{1}'.format(len(tmp_act), n_stim))
            tmp_act = np.array(tmp_act)
            raw_shape = tmp_act.shape
            tmp_act = tmp_act.reshape((raw_shape[0], raw_shape[1], -1))
            writer.set_act(ly, tmp_act)
            writer.set_attr(ly, 'raw_shape', raw_shape)
            writer.close()

        # --- read activation and count top ---
        reader = dio.ActReader(pjoin(args.out, title))
        tmp_act = reader.get_act(ly)
        tmp_act = dan.dnn_pooling(tmp_act, args.metric)
        tmp_act = reader.get_act(ly)
        top_result, chn_num = dan.dnn_top(tmp_act, args.top, args.metric, dmask_dict[ly]['chn'])
        if dmask_dict[ly]['chn'] == 'all':
            dmask_dict[ly]['chn'] = range(0, chn_num)
        for chn in enumerate(dmask_dict[ly]['chn']):
            csv_name = args.net + '.' + 'top' + str(args.top) + '.' + args.metric + '.' + ly + \
                '.' + str(chn[1]) + '.' + os.path.basename(args.stim)
            if not pexist(pjoin(args.out, csv_name)):
                tmp_stim_dict = copy.deepcopy(stim_dict)
                tmp_stim_dict['stim']['stimID'] = tmp_stim_dict['stim']['stimID'][list(top_result[chn[0]])]
                tmp_stim_dict['stim']['condition'] = tmp_stim_dict['stim']['condition'][list(top_result[chn[0]])]
                uio.save_stim_csv(pjoin(args.out, csv_name), tmp_stim_dict['title'], tmp_stim_dict['type'],
                                  tmp_stim_dict['path'], tmp_stim_dict['stim'])
            print(csv_name, 'is generated.')
        reader.close()


if __name__ == '__main__':
    main()
