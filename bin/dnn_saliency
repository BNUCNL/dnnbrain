#! /usr/bin/env python

"""
Find the saliency parts of an image that contributes to
the activation of the specified channel.
"""

import argparse
import numpy as np

from os.path import join as pjoin
from PIL import Image
from dnnbrain.dnn.base import ip
from dnnbrain.dnn.core import Stimulus
from dnnbrain.utils.plot import imgarray_show
from dnnbrain.dnn import models as db_models  # used by eval
from dnnbrain.dnn.algo import GuidedSaliencyImage, VanillaSaliencyImage


def main():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('-net',
                        metavar='Net',
                        required=True,
                        type=str,
                        help='a neural network name')
    parser.add_argument('-layer',
                        metavar='Layer',
                        required=True,
                        type=str,
                        help="convolution layers used to specify where activation is extracted from "
                             "For example, 'conv1' represents the first convolution layer.")
    parser.add_argument('-chn',
                        metavar='Channel',
                        required=True,
                        type=int,
                        nargs='+',
                        help="Channel numbers used to specify which channels are used to "
                             "extract feature maps")
    parser.add_argument('-stim',
                        metavar='Stimulus',
                        required=True,
                        type=str,
                        help='a .stim.csv file which contains stimulus information')
    parser.add_argument('-meth',
                        metavar='Method',
                        default='guided',
                        choices=('guided', 'vanilla'),
                        help='the method used to generate the saliency image')
    parser.add_argument('-cmap',
                        metavar='Colormap',
                        type=str,
                        default='coolwarm',
                        help='show feature maps with the specified colormap')
    parser.add_argument('-vmin',
                        metavar='Vmin',
                        type=float,
                        help='The minimal value used in colormap is applied in all feature maps.'
                             'Default is the minimal value of each feature map for itself.')
    parser.add_argument('-vmax',
                        metavar='Vmax',
                        type=float,
                        help='The maximal value used in colormap is applied in all feature maps.'
                             'Default is the maximal value of each feature map for itself.')
    parser.add_argument('-show',
                        action='store_true',
                        help='If used, display stimuli and feature maps in figures.')
    parser.add_argument('-out',
                        metavar='Output',
                        type=str,
                        help='an output directory where the figures are saved')
    args = parser.parse_args()
    assert len(args.chn) <= 5, "Don't support view more than 5 channels at once!"

    # load objects
    dnn = eval('db_models.{}()'.format(args.net))  # load DNN
    # load stimuli
    stimuli = Stimulus()
    stimuli.load(args.stim)
    # prepare saliency
    if args.meth == 'guided':
        saliency = GuidedSaliencyImage(dnn)
    else:
        saliency = VanillaSaliencyImage(dnn)

    # compute DNN activation batch-wise
    count = 1
    n_row = len(args.chn) + 1
    batch_size = 6
    n_stim = len(stimuli)
    batch_indices = list(range(0, n_stim, batch_size)) + [n_stim]
    for idx, bat_idx in enumerate(batch_indices[:-1]):
        stim = stimuli[bat_idx:batch_indices[idx+1]]

        # -prepare images-
        # prepare original images
        pil_imgs = []
        out_imgs = []
        for stim_id in stim.get('stimID'):
            img = Image.open(pjoin(stim.header['path'], stim_id))
            pil_imgs.append(img)
            out_imgs.append(np.array(img))
        # prepare saliency images
        for chn_num in args.chn:
            saliency.set_layer(args.layer, chn_num)
            for img in pil_imgs:
                grad = saliency.backprop(img)
                # grad = np.max(np.abs(grad), 0)
                grad = ip.to_pil(grad, True)
                out_imgs.append(np.array(grad))

        # -prepare row_names-
        row_names = ['chn{}'.format(chn) for chn in args.chn]
        row_names.insert(0, 'stim')

        # -prepare save path-
        if args.out is None:
            save_path = None
        else:
            save_path = pjoin(args.out, '{0}_{1}_fig{2}.jpg'.format(args.net, args.layer, count))

        n_col = len(stim)
        imgarray_show(out_imgs, n_row, n_col, row_names, args.vmin, args.vmax,
                      cmap=args.cmap, show=args.show, save_path=save_path)
        print('Finish: {0}/{1}'.format((count - 1) * batch_size + n_col, n_stim))
        count += 1


if __name__ == '__main__':
    main()
