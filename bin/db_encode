#! /usr/bin/env python

"""
Use DNN activation to encode brain
"""

import os
import time
import argparse
import numpy as np
import pandas as pd

from os.path import join as pjoin
from dnnbrain.dnn.core import Activation
from dnnbrain.brain.core import ROI, BrainEncoder
from dnnbrain.brain.io import load_brainimg, save_brainimg
from dnnbrain.utils.util import gen_dmask


def main():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('-anal',
                        metavar='Analysis',
                        required=True,
                        type=str,
                        choices=('uv', 'mv'),
                        help="uva: Do univariate analysis. "
                             "mva: Do multivariate analysis.")
    parser.add_argument('-act',
                        metavar='Activation',
                        required=True,
                        type=str,
                        help='DNN activation file')
    parser.add_argument('-layer',
                        metavar='Layer',
                        type=str,
                        nargs='+',
                        help="layer names of interest "
                             "For example, 'conv1' represents the first convolution layer, and "
                             "'fc1' represents the first full connection layer. ")
    parser.add_argument('-chn',
                        metavar='Channel',
                        type=int,
                        nargs='+',
                        help="channel numbers of interest "
                             "Default is using all channels of each layer specified by -layer.")
    parser.add_argument('-dmask',
                        metavar='DnnMask',
                        type=str,
                        help='a .dmask.csv file in which layers of interest are listed '
                             'with their own channels, rows and columns of interest.')
    parser.add_argument('-iteraxis',
                        type=str,
                        metavar='Axis',
                        choices=('channel', 'row_col'),
                        help="Iterate along the specified axis."
                             "If -anal is uva:"
                             "channel: Summarize the maximal prediction score for each channel. "
                             "row_col: Summarize the maximal prediction score for each location (row_idx, col_idx). "
                             "default: Summarize the maximal prediction score for the whole layer."
                             "If -anal is mva:"
                             "channel: Do mva using all units in each channel. "
                             "row_col: Do mva using all units in each location (row_idx, col_idx). "
                             "default: Do mva using all units in the whole layer.")
    parser.add_argument('-resp',
                        metavar='Response',
                        required=True,
                        type=str,
                        help='a .roi.h5/.nii file '
                             'If it is .nii file, -roi will be ignored. '
                             "All voxels' activation will be regarded as the "
                             "ground truth of a regression task. ")
    parser.add_argument('-bmask',
                        metavar='BrainMask',
                        type=str,
                        help='Brain mask is used to extract activation locally. '
                             'Only used when the response file is .nii file.')
    parser.add_argument('-roi',
                        metavar='RoiName',
                        type=str,
                        nargs='+',
                        help='Specify ROI names as the ground truth. '
                             'Default is using all ROIs in .roi.h5 file.')
    parser.add_argument('-model',
                        metavar='Model',
                        required=True,
                        type=str,
                        choices=('glm', 'lasso'),
                        help='Select a model to predict brain responses by dnn activation. '
                             'Use glm (general linear model) for regression. '
                             'Use lasso (lasso regression) for regression.')
    parser.add_argument('-scoring',
                        metavar='Scoring',
                        type=str,
                        default='explained_variance',
                        help="model evaluation rules: "
                             "correlation or sklearn scoring parameters"
                             "Default is explained_variance.")
    parser.add_argument('-cv',
                        metavar='CrossValidationFoldNumber',
                        type=int,
                        default=3,
                        help='cross validation fold number')
    parser.add_argument('-out',
                        metavar='Output',
                        required=True,
                        type=str,
                        help='an output directory')
    args = parser.parse_args()

    # -Load response start-
    if args.resp.endswith('.roi.h5'):
        roi = ROI()
        roi.load(args.resp, args.roi)
        Y = roi.data

    elif args.resp.endswith('.nii') or args.resp.endswith('.nii.gz'):
        Y, header = load_brainimg(args.resp)
        bshape = Y.shape[1:]

        # Get resp data within brain mask
        if args.bmask is None:
            bmask = np.any(Y, 0)
        else:
            bmask, _ = load_brainimg(args.bmask, ismask=True)
            assert bshape == bmask.shape, 'brain mask and brain response mismatched in space'
            bmask = bmask.astype(np.bool)
        Y = Y[:, bmask]

    else:
        raise IOError('Only .roi.h5 and nifti/cifti are supported')
    print('Finish loading response: ', args.resp)
    # -Load response end-

    # -load activation start-
    # initialize DNN mask
    if args.layer is None and args.dmask is None:
        dmask = None
    else:
        channels = 'all' if args.chn is None else args.chn
        dmask = gen_dmask(args.layer, channels, args.dmask)
    activation = Activation()
    activation.load(args.act, dmask)
    print('Finish loading activation: ', args.act)
    # -load activation end-

    # -prediction start-
    time1 = time.time()
    encoder = BrainEncoder(Y, args.anal, args.model, args.cv, args.scoring)
    encode_dict = encoder.encode_dnn(activation, args.iteraxis)
    print('Finish prediction: cost {} seconds.'.format(time.time()-time1))
    # -prediction end-

    # -save out start-
    for layer, data in encode_dict.items():
        # prepare directory
        trg_dir = pjoin(args.out, layer)
        if not os.path.isdir(trg_dir):
            os.makedirs(trg_dir)
        if args.iteraxis is not None:
            trg_dir = pjoin(trg_dir, args.iteraxis)
            if not os.path.isdir(trg_dir):
                os.makedirs(trg_dir)

        # save files
        if args.resp.endswith('.roi.h5'):
            for k, v in data.items():
                if k == 'max_score':
                    df = pd.DataFrame(v, columns=roi.rois)
                    df.to_csv(pjoin(trg_dir, '{}.csv'.format(k)), index=False)
                else:
                    np.save(pjoin(trg_dir, k), v)

        elif args.resp.endswith('.nii') or args.resp.endswith('.nii.gz'):
            resp_suffix = '.'.join(args.resp.split('.')[1:])

            bshape_pos = list(range(1, len(bshape)+1))
            for k, v in data.items():
                if k == 'max_score':
                    img = np.zeros((v.shape[0], *bshape))
                    img[:, bmask] = v
                    save_brainimg(pjoin(trg_dir, '{}.{}'.format(k, resp_suffix)), img, header)
                elif 'model' in k:
                    arr = np.zeros((v.shape[0], *bshape), dtype=np.object)
                    arr[:, bmask] = v
                    arr = arr.transpose((*bshape_pos, 0))
                    np.save(pjoin(trg_dir, k), arr)
                elif k == 'max_loc':
                    arr = np.zeros((v.shape[0], *bshape, v.shape[-1]))
                    arr[:, bmask, :] = v
                    arr = arr.transpose((*bshape_pos, 0, -1))
                    np.save(pjoin(trg_dir, k), arr)
                elif k == 'score':
                    # save all cross validation scores
                    arr = np.zeros((v.shape[0], *bshape, v.shape[-1]))
                    arr[:, bmask, :] = v
                    arr = arr.transpose((*bshape_pos, 0, -1))
                    np.save(pjoin(trg_dir, k), arr)
                    # save mean scores of each cross validation
                    img = np.zeros((v.shape[0], *bshape))
                    img[:, bmask] = np.mean(v, 2)
                    save_brainimg(pjoin(trg_dir, '{}.{}'.format(k, resp_suffix)), img, header)

        print('Finish save {}.'.format(layer))
    # -save out end-


if __name__ == '__main__':
    main()
